2017-08-15 11:29:49,732 [main] INFO  schedule.Engine - 
DataX engine [version=1] storage[com.taobao.datax.engine.storage.RAMStorage size 3000/1000000 buffer 50] pluginpath[/data1/test/datax/plugins/]

2017-08-15 11:29:49,745 [main] INFO  schedule.Engine - 

job:FtpReader_to_StreamWriter_job
Reader conf:
name:ftpreader id virgin-reader, pool(1) destruct(0)
params:
	                     port=[22                            ]
	                 protocol=[sftp                          ]
	                     host=[127.0.0.1                     ]
	                  columns=[*                             ]
	                    where=[?                             ]
	                 password=[******                        ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	                 username=[zhuhq                         ]
	                      sql=[?                             ]
	              concurrency=[1                             ]
	                     path=[/data1/test/testjsxf          ]
	                 encoding=[UTF-8                         ]
	             mysql.params=[?                             ]

Writer conf [num 1]:
name:streamwriter id virgin-writer, pool(1) destruct(0)
params:
	          hiveserver_port=[10000                         ]
	                 nullchar=[?                             ]
	         partition_values=[?                             ]
	                 interval=[0                             ]
	              buffer_size=[4096                          ]
	                key_class=[org.apache.hadoop.io.Text     ]
	            hiveserver_ip=[?                             ]
	          partition_names=[?                             ]
	         compression_type=[NONE                          ]
	                    print=[true                          ]
	          key_field_index=[0                             ]
	                file_type=[TXT                           ]
	                 del_mode=[3                             ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	               table_name=[?                             ]
	         hivetable_switch=[false                         ]
	              concurrency=[1                             ]
	                 encoding=[UTF-8                         ]
	              hadoop_conf=[?                             ]
	          prefix_filename=[part                          ]
	               line_split=[\n                            ]
	              field_split=[,                             ]
	              value_class=[org.apache.hadoop.io.Text     ]
	              codec_class=[org.apache.hadoop.io.compress.DefaultCodec]

2017-08-15 11:29:49,745 [main] INFO  schedule.Engine - DataX startups .
2017-08-15 11:29:49,745 [main] INFO  schedule.Engine - reader plugin:ftpreader
2017-08-15 11:29:49,748 [main] INFO  schedule.Engine - pluginName:ftpreader
2017-08-15 11:29:49,748 [main] INFO  schedule.Engine - replace hdfs reader to hive reader check
2017-08-15 11:29:49,748 [main] INFO  schedule.Engine - path:/data1/test/datax/plugins/reader/ftpreader
2017-08-15 11:29:49,748 [main] INFO  schedule.Engine - DataX Reader ftpreader try to load path /data1/test/datax/plugins/reader/ftpreader .
2017-08-15 11:29:49,752 [main] INFO  schedule.PluginWorker - init begin
2017-08-15 11:29:49,758 [main] INFO  schedule.PluginWorker - init end
2017-08-15 11:29:49,758 [main] INFO  schedule.Engine - DataX Reader prepare work begins .
2017-08-15 11:29:49,758 [main] INFO  schedule.PluginWorker - prepare begin
2017-08-15 11:29:49,758 [main] INFO  schedule.PluginWorker - prepare end
2017-08-15 11:29:49,758 [main] INFO  schedule.Engine - DataX Reader prepare work ends .
2017-08-15 11:29:49,758 [main] INFO  schedule.Engine - DataX Reader split work begins .
2017-08-15 11:29:49,758 [main] INFO  schedule.PluginWorker - doSplit begin
2017-08-15 11:29:50,861 [main] INFO  ftpreader.FtpReader - read metadata from file begin
2017-08-15 11:29:50,861 [main] ERROR ftpreader.SftpHelper - 请确认您的配置项path:[/data1/test/testjsxf/__metadata]存在，且配置的用户有权限读取
2017-08-15 11:29:50,862 [main] ERROR ftpreader.FtpReader - init metadata error
请确认您的配置项path:[/data1/test/testjsxf/__metadata]存在，且配置的用户有权限读取
	at com.taobao.datax.plugins.reader.ftpreader.SftpHelper.isFileExist(SftpHelper.java:119)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.initMetadata(FtpReader.java:82)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.split(FtpReader.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.taobao.datax.engine.schedule.PluginWorker.doSplit(PluginWorker.java:222)
	at com.taobao.datax.engine.schedule.Engine.initReaderPool(Engine.java:308)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:96)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-08-15 11:29:50,876 [main] INFO  ftpreader.FtpReader - 您即将读取的文件数为: [2]
2017-08-15 11:29:50,878 [main] INFO  schedule.PluginWorker - doSplit end
2017-08-15 11:29:50,879 [main] INFO  schedule.Engine - DataX Reader splits this job into 0 sub-jobs
2017-08-15 11:29:50,879 [main] INFO  schedule.Engine - DataX Reader split work ends .
2017-08-15 11:29:50,881 [main] INFO  schedule.Engine - DataX Reader starts to read data .
2017-08-15 11:29:50,881 [main] INFO  schedule.Engine - DataX Writer streamwriter try to load path /data1/test/datax/plugins/writer/streamwriter .
2017-08-15 11:29:50,883 [main] INFO  schedule.PluginWorker - init begin
2017-08-15 11:29:50,883 [main] INFO  schedule.PluginWorker - init end
2017-08-15 11:29:50,883 [main] INFO  schedule.Engine - DataX Writer prepare work begins .
2017-08-15 11:29:50,883 [main] INFO  schedule.PluginWorker - prepare begin
2017-08-15 11:29:50,883 [main] INFO  schedule.PluginWorker - prepare end
2017-08-15 11:29:50,883 [main] INFO  schedule.Engine - DataX Writer prepare work ends .
2017-08-15 11:29:50,883 [main] INFO  schedule.Engine - DataX Writer split work begins .
2017-08-15 11:29:50,883 [main] INFO  schedule.PluginWorker - doSplit begin
2017-08-15 11:29:50,883 [main] INFO  schedule.PluginWorker - doSplit end
2017-08-15 11:29:50,883 [main] INFO  schedule.Engine - DataX Writer splits this job into 1 sub-jobs .
2017-08-15 11:29:50,883 [main] INFO  schedule.Engine - DataX Writer split work ends .
2017-08-15 11:29:50,884 [main] INFO  schedule.Engine - DataX Writer starts to write data .
2017-08-15 11:29:50,885 [main] INFO  schedule.Engine - DataX starts to exchange data .
2017-08-15 11:29:50,886 [pool-2-thread-1] INFO  schedule.WriterWorker - begin execute finish in finally code:0
2017-08-15 11:29:50,886 [pool-2-thread-1] INFO  schedule.WriterWorker - execute finish in finally code:0
2017-08-15 11:29:50,886 [pool-2-thread-1] INFO  schedule.WriterWorker - call result msg:null is success:true
2017-08-15 11:29:51,886 [main] INFO  schedule.Engine - DataX Reader post work begins .
2017-08-15 11:29:51,886 [main] INFO  schedule.PluginWorker - post begin
2017-08-15 11:29:51,887 [main] INFO  schedule.PluginWorker - post end
2017-08-15 11:29:51,887 [main] INFO  schedule.Engine - DataX Reader post work ends .
2017-08-15 11:29:51,887 [main] INFO  schedule.Engine - DataX Writers post work begins .
2017-08-15 11:29:51,887 [main] INFO  schedule.PluginWorker - post begin
2017-08-15 11:29:51,887 [main] INFO  schedule.PluginWorker - post end
2017-08-15 11:29:51,887 [main] INFO  schedule.Engine - DataX Writers post work ends .
2017-08-15 11:29:51,887 [main] INFO  schedule.Engine - DataX job succeed .
2017-08-15 11:29:51,887 [main] INFO  schedule.Engine - check status twice begin
2017-08-15 11:29:51,887 [main] INFO  schedule.Engine - dps length:1
2017-08-15 11:29:51,888 [main] INFO  schedule.Engine - check status twice end
2017-08-15 11:29:51,893 [main] INFO  schedule.Engine - 
DataX starts work at      : 2017-08-15 11:29:49
DataX ends work at        : 2017-08-15 11:29:51
Total time costs          :                  2s
Average byte speed        :                0B/s
Average line speed        :                0L/s
Total transferred records :                   0
Total discarded records   :                   0

2017-08-15 11:29:56,943 [main] INFO  schedule.Reporter - Report DataX statistic(null) failed
java.net.SocketTimeoutException: connect timed out
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:997)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:933)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:851)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1301)
	at com.taobao.datax.engine.schedule.Reporter.report(Reporter.java:116)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:225)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-08-15 11:29:59,946 [main] INFO  schedule.Engine - 
DataX engine [version=1] storage[com.taobao.datax.engine.storage.RAMStorage size 3000/1000000 buffer 50] pluginpath[/data1/test/datax/plugins/]

2017-08-15 11:29:59,961 [main] INFO  schedule.Engine - 

job:FtpReader_to_StreamWriter_job
Reader conf:
name:ftpreader id virgin-reader, pool(1) destruct(0)
params:
	                     port=[22                            ]
	                 protocol=[sftp                          ]
	                     host=[127.0.0.1                     ]
	                  columns=[*                             ]
	                    where=[?                             ]
	                 password=[******                        ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	                 username=[zhuhq                         ]
	                      sql=[?                             ]
	              concurrency=[1                             ]
	                     path=[/data1/test/testjsxf          ]
	                 encoding=[UTF-8                         ]
	             mysql.params=[?                             ]

Writer conf [num 1]:
name:streamwriter id virgin-writer, pool(1) destruct(0)
params:
	          hiveserver_port=[10000                         ]
	                 nullchar=[?                             ]
	         partition_values=[?                             ]
	                 interval=[0                             ]
	              buffer_size=[4096                          ]
	                key_class=[org.apache.hadoop.io.Text     ]
	            hiveserver_ip=[?                             ]
	          partition_names=[?                             ]
	         compression_type=[NONE                          ]
	                    print=[true                          ]
	          key_field_index=[0                             ]
	                file_type=[TXT                           ]
	                 del_mode=[3                             ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	               table_name=[?                             ]
	         hivetable_switch=[false                         ]
	              concurrency=[1                             ]
	                 encoding=[UTF-8                         ]
	              hadoop_conf=[?                             ]
	          prefix_filename=[part                          ]
	               line_split=[\n                            ]
	              field_split=[,                             ]
	              value_class=[org.apache.hadoop.io.Text     ]
	              codec_class=[org.apache.hadoop.io.compress.DefaultCodec]

2017-08-15 11:29:59,962 [main] INFO  schedule.Engine - DataX startups .
2017-08-15 11:29:59,962 [main] INFO  schedule.Engine - reader plugin:ftpreader
2017-08-15 11:29:59,962 [main] INFO  schedule.Engine - pluginName:ftpreader
2017-08-15 11:29:59,962 [main] INFO  schedule.Engine - replace hdfs reader to hive reader check
2017-08-15 11:29:59,962 [main] INFO  schedule.Engine - path:/data1/test/datax/plugins/reader/ftpreader
2017-08-15 11:29:59,963 [main] INFO  schedule.PluginWorker - init begin
2017-08-15 11:29:59,963 [main] INFO  schedule.PluginWorker - init end
2017-08-15 11:29:59,963 [main] INFO  schedule.Engine - DataX Reader prepare work begins .
2017-08-15 11:29:59,963 [main] INFO  schedule.PluginWorker - prepare begin
2017-08-15 11:29:59,963 [main] INFO  schedule.PluginWorker - prepare end
2017-08-15 11:29:59,964 [main] INFO  schedule.Engine - DataX Reader prepare work ends .
2017-08-15 11:29:59,964 [main] INFO  schedule.Engine - DataX Reader split work begins .
2017-08-15 11:29:59,964 [main] INFO  schedule.PluginWorker - doSplit begin
2017-08-15 11:30:00,162 [main] INFO  ftpreader.FtpReader - read metadata from file begin
2017-08-15 11:30:00,165 [main] ERROR ftpreader.SftpHelper - 请确认您的配置项path:[/data1/test/testjsxf/__metadata]存在，且配置的用户有权限读取
2017-08-15 11:30:00,165 [main] ERROR ftpreader.FtpReader - init metadata error
请确认您的配置项path:[/data1/test/testjsxf/__metadata]存在，且配置的用户有权限读取
	at com.taobao.datax.plugins.reader.ftpreader.SftpHelper.isFileExist(SftpHelper.java:119)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.initMetadata(FtpReader.java:82)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.split(FtpReader.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.taobao.datax.engine.schedule.PluginWorker.doSplit(PluginWorker.java:222)
	at com.taobao.datax.engine.schedule.Engine.initReaderPool(Engine.java:308)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:96)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-08-15 11:30:00,204 [main] INFO  ftpreader.FtpReader - 您即将读取的文件数为: [2]
2017-08-15 11:30:00,204 [main] INFO  schedule.PluginWorker - doSplit end
2017-08-15 11:30:00,204 [main] INFO  schedule.Engine - DataX Reader splits this job into 0 sub-jobs
2017-08-15 11:30:00,205 [main] INFO  schedule.Engine - DataX Reader split work ends .
2017-08-15 11:30:00,205 [main] INFO  schedule.Engine - DataX Reader starts to read data .
2017-08-15 11:30:00,206 [main] INFO  schedule.PluginWorker - init begin
2017-08-15 11:30:00,206 [main] INFO  schedule.PluginWorker - init end
2017-08-15 11:30:00,206 [main] INFO  schedule.Engine - DataX Writer prepare work begins .
2017-08-15 11:30:00,206 [main] INFO  schedule.PluginWorker - prepare begin
2017-08-15 11:30:00,206 [main] INFO  schedule.PluginWorker - prepare end
2017-08-15 11:30:00,206 [main] INFO  schedule.Engine - DataX Writer prepare work ends .
2017-08-15 11:30:00,206 [main] INFO  schedule.Engine - DataX Writer split work begins .
2017-08-15 11:30:00,206 [main] INFO  schedule.PluginWorker - doSplit begin
2017-08-15 11:30:00,206 [main] INFO  schedule.PluginWorker - doSplit end
2017-08-15 11:30:00,206 [main] INFO  schedule.Engine - DataX Writer splits this job into 1 sub-jobs .
2017-08-15 11:30:00,206 [main] INFO  schedule.Engine - DataX Writer split work ends .
2017-08-15 11:30:00,207 [main] INFO  schedule.Engine - DataX Writer starts to write data .
2017-08-15 11:30:00,207 [main] INFO  schedule.Engine - DataX starts to exchange data .
2017-08-15 11:30:01,207 [pool-4-thread-1] INFO  schedule.WriterWorker - begin execute finish in finally code:0
2017-08-15 11:30:01,208 [pool-4-thread-1] INFO  schedule.WriterWorker - execute finish in finally code:0
2017-08-15 11:30:01,208 [pool-4-thread-1] INFO  schedule.WriterWorker - call result msg:null is success:true
2017-08-15 11:30:02,207 [main] INFO  schedule.Engine - DataX Reader post work begins .
2017-08-15 11:30:02,208 [main] INFO  schedule.PluginWorker - post begin
2017-08-15 11:30:02,208 [main] INFO  schedule.PluginWorker - post end
2017-08-15 11:30:02,208 [main] INFO  schedule.Engine - DataX Reader post work ends .
2017-08-15 11:30:02,208 [main] INFO  schedule.Engine - DataX Writers post work begins .
2017-08-15 11:30:02,209 [main] INFO  schedule.PluginWorker - post begin
2017-08-15 11:30:02,209 [main] INFO  schedule.PluginWorker - post end
2017-08-15 11:30:02,209 [main] INFO  schedule.Engine - DataX Writers post work ends .
2017-08-15 11:30:02,209 [main] INFO  schedule.Engine - DataX job succeed .
2017-08-15 11:30:02,209 [main] INFO  schedule.Engine - check status twice begin
2017-08-15 11:30:02,209 [main] INFO  schedule.Engine - dps length:1
2017-08-15 11:30:02,209 [main] INFO  schedule.Engine - check status twice end
2017-08-15 11:30:02,212 [main] INFO  schedule.Engine - 
DataX starts work at      : 2017-08-15 11:29:59
DataX ends work at        : 2017-08-15 11:30:02
Total time costs          :                  2s
Average byte speed        :                0B/s
Average line speed        :                0L/s
Total transferred records :                   0
Total discarded records   :                   0

2017-08-15 11:30:07,223 [main] INFO  schedule.Reporter - Report DataX statistic(null) failed
java.net.SocketTimeoutException: connect timed out
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:997)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:933)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:851)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1301)
	at com.taobao.datax.engine.schedule.Reporter.report(Reporter.java:116)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:225)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-08-15 11:30:10,226 [main] INFO  schedule.Engine - 
DataX engine [version=1] storage[com.taobao.datax.engine.storage.RAMStorage size 3000/1000000 buffer 50] pluginpath[/data1/test/datax/plugins/]

2017-08-15 11:30:10,233 [main] INFO  schedule.Engine - 

job:FtpReader_to_StreamWriter_job
Reader conf:
name:ftpreader id virgin-reader, pool(1) destruct(0)
params:
	                     port=[22                            ]
	                 protocol=[sftp                          ]
	                     host=[127.0.0.1                     ]
	                  columns=[*                             ]
	                    where=[?                             ]
	                 password=[******                        ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	                 username=[zhuhq                         ]
	                      sql=[?                             ]
	              concurrency=[1                             ]
	                     path=[/data1/test/testjsxf          ]
	                 encoding=[UTF-8                         ]
	             mysql.params=[?                             ]

Writer conf [num 1]:
name:streamwriter id virgin-writer, pool(1) destruct(0)
params:
	          hiveserver_port=[10000                         ]
	                 nullchar=[?                             ]
	         partition_values=[?                             ]
	                 interval=[0                             ]
	              buffer_size=[4096                          ]
	                key_class=[org.apache.hadoop.io.Text     ]
	            hiveserver_ip=[?                             ]
	          partition_names=[?                             ]
	         compression_type=[NONE                          ]
	                    print=[true                          ]
	          key_field_index=[0                             ]
	                file_type=[TXT                           ]
	                 del_mode=[3                             ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	               table_name=[?                             ]
	         hivetable_switch=[false                         ]
	              concurrency=[1                             ]
	                 encoding=[UTF-8                         ]
	              hadoop_conf=[?                             ]
	          prefix_filename=[part                          ]
	               line_split=[\n                            ]
	              field_split=[,                             ]
	              value_class=[org.apache.hadoop.io.Text     ]
	              codec_class=[org.apache.hadoop.io.compress.DefaultCodec]

2017-08-15 11:30:10,233 [main] INFO  schedule.Engine - DataX startups .
2017-08-15 11:30:10,233 [main] INFO  schedule.Engine - reader plugin:ftpreader
2017-08-15 11:30:10,233 [main] INFO  schedule.Engine - pluginName:ftpreader
2017-08-15 11:30:10,233 [main] INFO  schedule.Engine - replace hdfs reader to hive reader check
2017-08-15 11:30:10,233 [main] INFO  schedule.Engine - path:/data1/test/datax/plugins/reader/ftpreader
2017-08-15 11:30:10,233 [main] INFO  schedule.PluginWorker - init begin
2017-08-15 11:30:10,233 [main] INFO  schedule.PluginWorker - init end
2017-08-15 11:30:10,233 [main] INFO  schedule.Engine - DataX Reader prepare work begins .
2017-08-15 11:30:10,233 [main] INFO  schedule.PluginWorker - prepare begin
2017-08-15 11:30:10,234 [main] INFO  schedule.PluginWorker - prepare end
2017-08-15 11:30:10,234 [main] INFO  schedule.Engine - DataX Reader prepare work ends .
2017-08-15 11:30:10,234 [main] INFO  schedule.Engine - DataX Reader split work begins .
2017-08-15 11:30:10,234 [main] INFO  schedule.PluginWorker - doSplit begin
2017-08-15 11:30:10,425 [main] INFO  ftpreader.FtpReader - read metadata from file begin
2017-08-15 11:30:10,426 [main] ERROR ftpreader.SftpHelper - 请确认您的配置项path:[/data1/test/testjsxf/__metadata]存在，且配置的用户有权限读取
2017-08-15 11:30:10,427 [main] ERROR ftpreader.FtpReader - init metadata error
请确认您的配置项path:[/data1/test/testjsxf/__metadata]存在，且配置的用户有权限读取
	at com.taobao.datax.plugins.reader.ftpreader.SftpHelper.isFileExist(SftpHelper.java:119)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.initMetadata(FtpReader.java:82)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.split(FtpReader.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.taobao.datax.engine.schedule.PluginWorker.doSplit(PluginWorker.java:222)
	at com.taobao.datax.engine.schedule.Engine.initReaderPool(Engine.java:308)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:96)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-08-15 11:30:10,460 [main] INFO  ftpreader.FtpReader - 您即将读取的文件数为: [2]
2017-08-15 11:30:10,461 [main] INFO  schedule.PluginWorker - doSplit end
2017-08-15 11:30:10,462 [main] INFO  schedule.Engine - DataX Reader splits this job into 0 sub-jobs
2017-08-15 11:30:10,462 [main] INFO  schedule.Engine - DataX Reader split work ends .
2017-08-15 11:30:10,463 [main] INFO  schedule.Engine - DataX Reader starts to read data .
2017-08-15 11:30:10,463 [main] INFO  schedule.PluginWorker - init begin
2017-08-15 11:30:10,463 [main] INFO  schedule.PluginWorker - init end
2017-08-15 11:30:10,463 [main] INFO  schedule.Engine - DataX Writer prepare work begins .
2017-08-15 11:30:10,464 [main] INFO  schedule.PluginWorker - prepare begin
2017-08-15 11:30:10,464 [main] INFO  schedule.PluginWorker - prepare end
2017-08-15 11:30:10,464 [main] INFO  schedule.Engine - DataX Writer prepare work ends .
2017-08-15 11:30:10,464 [main] INFO  schedule.Engine - DataX Writer split work begins .
2017-08-15 11:30:10,464 [main] INFO  schedule.PluginWorker - doSplit begin
2017-08-15 11:30:10,464 [main] INFO  schedule.PluginWorker - doSplit end
2017-08-15 11:30:10,464 [main] INFO  schedule.Engine - DataX Writer splits this job into 1 sub-jobs .
2017-08-15 11:30:10,464 [main] INFO  schedule.Engine - DataX Writer split work ends .
2017-08-15 11:30:10,467 [main] INFO  schedule.Engine - DataX Writer starts to write data .
2017-08-15 11:30:10,467 [main] INFO  schedule.Engine - DataX starts to exchange data .
2017-08-15 11:30:11,468 [pool-6-thread-1] INFO  schedule.WriterWorker - begin execute finish in finally code:0
2017-08-15 11:30:11,469 [pool-6-thread-1] INFO  schedule.WriterWorker - execute finish in finally code:0
2017-08-15 11:30:11,469 [pool-6-thread-1] INFO  schedule.WriterWorker - call result msg:null is success:true
2017-08-15 11:30:12,468 [main] INFO  schedule.Engine - DataX Reader post work begins .
2017-08-15 11:30:12,469 [main] INFO  schedule.PluginWorker - post begin
2017-08-15 11:30:12,469 [main] INFO  schedule.PluginWorker - post end
2017-08-15 11:30:12,469 [main] INFO  schedule.Engine - DataX Reader post work ends .
2017-08-15 11:30:12,469 [main] INFO  schedule.Engine - DataX Writers post work begins .
2017-08-15 11:30:12,469 [main] INFO  schedule.PluginWorker - post begin
2017-08-15 11:30:12,469 [main] INFO  schedule.PluginWorker - post end
2017-08-15 11:30:12,469 [main] INFO  schedule.Engine - DataX Writers post work ends .
2017-08-15 11:30:12,470 [main] INFO  schedule.Engine - DataX job succeed .
2017-08-15 11:30:12,470 [main] INFO  schedule.Engine - check status twice begin
2017-08-15 11:30:12,470 [main] INFO  schedule.Engine - dps length:1
2017-08-15 11:30:12,470 [main] INFO  schedule.Engine - check status twice end
2017-08-15 11:30:12,472 [main] INFO  schedule.Engine - 
DataX starts work at      : 2017-08-15 11:30:10
DataX ends work at        : 2017-08-15 11:30:12
Total time costs          :                  2s
Average byte speed        :                0B/s
Average line speed        :                0L/s
Total transferred records :                   0
Total discarded records   :                   0

2017-08-15 11:30:17,483 [main] INFO  schedule.Reporter - Report DataX statistic(null) failed
java.net.SocketTimeoutException: connect timed out
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
	at sun.net.www.http.HttpClient.New(HttpClient.java:308)
	at sun.net.www.http.HttpClient.New(HttpClient.java:326)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:997)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:933)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:851)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1301)
	at com.taobao.datax.engine.schedule.Reporter.report(Reporter.java:116)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:225)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-08-15 11:30:20,486 [main] INFO  schedule.Engine - 
DataX engine [version=1] storage[com.taobao.datax.engine.storage.RAMStorage size 3000/1000000 buffer 50] pluginpath[/data1/test/datax/plugins/]

2017-08-15 11:30:20,498 [main] INFO  schedule.Engine - 

job:FtpReader_to_StreamWriter_job
Reader conf:
name:ftpreader id virgin-reader, pool(1) destruct(0)
params:
	                     port=[22                            ]
	                 protocol=[sftp                          ]
	                     host=[127.0.0.1                     ]
	                  columns=[*                             ]
	                    where=[?                             ]
	                 password=[******                        ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	                 username=[zhuhq                         ]
	                      sql=[?                             ]
	              concurrency=[1                             ]
	                     path=[/data1/test/testjsxf          ]
	                 encoding=[UTF-8                         ]
	             mysql.params=[?                             ]

Writer conf [num 1]:
name:streamwriter id virgin-writer, pool(1) destruct(0)
params:
	          hiveserver_port=[10000                         ]
	                 nullchar=[?                             ]
	         partition_values=[?                             ]
	                 interval=[0                             ]
	              buffer_size=[4096                          ]
	                key_class=[org.apache.hadoop.io.Text     ]
	            hiveserver_ip=[?                             ]
	          partition_names=[?                             ]
	         compression_type=[NONE                          ]
	                    print=[true                          ]
	          key_field_index=[0                             ]
	                file_type=[TXT                           ]
	                 del_mode=[3                             ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	               table_name=[?                             ]
	         hivetable_switch=[false                         ]
	              concurrency=[1                             ]
	                 encoding=[UTF-8                         ]
	              hadoop_conf=[?                             ]
	          prefix_filename=[part                          ]
	               line_split=[\n                            ]
	              field_split=[,                             ]
	              value_class=[org.apache.hadoop.io.Text     ]
	              codec_class=[org.apache.hadoop.io.compress.DefaultCodec]

2017-08-15 11:30:20,498 [main] INFO  schedule.Engine - DataX startups .
2017-08-15 11:30:20,499 [main] INFO  schedule.Engine - reader plugin:ftpreader
2017-08-15 11:30:20,499 [main] INFO  schedule.Engine - pluginName:ftpreader
2017-08-15 11:30:20,499 [main] INFO  schedule.Engine - replace hdfs reader to hive reader check
2017-08-15 11:30:20,499 [main] INFO  schedule.Engine - path:/data1/test/datax/plugins/reader/ftpreader
2017-08-15 11:30:20,500 [main] INFO  schedule.PluginWorker - init begin
2017-08-15 11:30:20,500 [main] INFO  schedule.PluginWorker - init end
2017-08-15 11:30:20,500 [main] INFO  schedule.Engine - DataX Reader prepare work begins .
2017-08-15 11:30:20,500 [main] INFO  schedule.PluginWorker - prepare begin
2017-08-15 11:30:20,500 [main] INFO  schedule.PluginWorker - prepare end
2017-08-15 11:30:20,501 [main] INFO  schedule.Engine - DataX Reader prepare work ends .
2017-08-15 11:30:20,501 [main] INFO  schedule.Engine - DataX Reader split work begins .
2017-08-15 11:30:20,501 [main] INFO  schedule.PluginWorker - doSplit begin
2017-08-15 11:30:20,520 [main] ERROR ftpreader.SftpHelper - jsch exception:
com.jcraft.jsch.JSchException: verify: false
	at com.jcraft.jsch.Session.connect(Session.java:295)
	at com.jcraft.jsch.Session.connect(Session.java:150)
	at com.taobao.datax.plugins.reader.ftpreader.SftpHelper.loginFtpServer(SftpHelper.java:37)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.initFtpHelperAndLogin(FtpReader.java:77)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.split(FtpReader.java:109)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.taobao.datax.engine.schedule.PluginWorker.doSplit(PluginWorker.java:222)
	at com.taobao.datax.engine.schedule.Engine.initReaderPool(Engine.java:308)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:96)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-08-15 11:30:20,521 [main] ERROR ftpreader.SftpHelper - 与ftp服务器建立连接失败 : [message:host =127.0.0.1,username = zhuhq,port =22]
2017-08-15 11:30:20,521 [main] ERROR schedule.PluginWorker - doSplit error:
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.taobao.datax.engine.schedule.PluginWorker.doSplit(PluginWorker.java:222)
	at com.taobao.datax.engine.schedule.Engine.initReaderPool(Engine.java:308)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:96)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
Caused by: 与ftp服务器建立连接失败 : [message:host =127.0.0.1,username = zhuhq,port =22]
	at com.taobao.datax.plugins.reader.ftpreader.SftpHelper.loginFtpServer(SftpHelper.java:72)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.initFtpHelperAndLogin(FtpReader.java:77)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.split(FtpReader.java:109)
	... 13 more
2017-08-15 11:30:20,522 [main] ERROR schedule.Engine - null
	at com.taobao.datax.engine.schedule.PluginWorker.doSplit(PluginWorker.java:228)
	at com.taobao.datax.engine.schedule.Engine.initReaderPool(Engine.java:308)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:96)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)

2017-08-15 11:30:23,522 [main] INFO  schedule.Engine - 
DataX engine [version=1] storage[com.taobao.datax.engine.storage.RAMStorage size 3000/1000000 buffer 50] pluginpath[/data1/test/datax/plugins/]

2017-08-15 11:30:23,526 [main] INFO  schedule.Engine - 

job:FtpReader_to_StreamWriter_job
Reader conf:
name:ftpreader id virgin-reader, pool(1) destruct(0)
params:
	                     port=[22                            ]
	                 protocol=[sftp                          ]
	                     host=[127.0.0.1                     ]
	                  columns=[*                             ]
	                    where=[?                             ]
	                 password=[******                        ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	                 username=[zhuhq                         ]
	                      sql=[?                             ]
	              concurrency=[1                             ]
	                     path=[/data1/test/testjsxf          ]
	                 encoding=[UTF-8                         ]
	             mysql.params=[?                             ]

Writer conf [num 1]:
name:streamwriter id virgin-writer, pool(1) destruct(0)
params:
	          hiveserver_port=[10000                         ]
	                 nullchar=[?                             ]
	         partition_values=[?                             ]
	                 interval=[0                             ]
	              buffer_size=[4096                          ]
	                key_class=[org.apache.hadoop.io.Text     ]
	            hiveserver_ip=[?                             ]
	          partition_names=[?                             ]
	         compression_type=[NONE                          ]
	                    print=[true                          ]
	          key_field_index=[0                             ]
	                file_type=[TXT                           ]
	                 del_mode=[3                             ]
	           have_read_file=[/data1/test/testjsxf_havereadfile]
	               table_name=[?                             ]
	         hivetable_switch=[false                         ]
	              concurrency=[1                             ]
	                 encoding=[UTF-8                         ]
	              hadoop_conf=[?                             ]
	          prefix_filename=[part                          ]
	               line_split=[\n                            ]
	              field_split=[,                             ]
	              value_class=[org.apache.hadoop.io.Text     ]
	              codec_class=[org.apache.hadoop.io.compress.DefaultCodec]

2017-08-15 11:30:23,526 [main] INFO  schedule.Engine - DataX startups .
2017-08-15 11:30:23,526 [main] INFO  schedule.Engine - reader plugin:ftpreader
2017-08-15 11:30:23,526 [main] INFO  schedule.Engine - pluginName:ftpreader
2017-08-15 11:30:23,526 [main] INFO  schedule.Engine - replace hdfs reader to hive reader check
2017-08-15 11:30:23,526 [main] INFO  schedule.Engine - path:/data1/test/datax/plugins/reader/ftpreader
2017-08-15 11:30:23,526 [main] INFO  schedule.PluginWorker - init begin
2017-08-15 11:30:23,526 [main] INFO  schedule.PluginWorker - init end
2017-08-15 11:30:23,526 [main] INFO  schedule.Engine - DataX Reader prepare work begins .
2017-08-15 11:30:23,526 [main] INFO  schedule.PluginWorker - prepare begin
2017-08-15 11:30:23,526 [main] INFO  schedule.PluginWorker - prepare end
2017-08-15 11:30:23,526 [main] INFO  schedule.Engine - DataX Reader prepare work ends .
2017-08-15 11:30:23,526 [main] INFO  schedule.Engine - DataX Reader split work begins .
2017-08-15 11:30:23,526 [main] INFO  schedule.PluginWorker - doSplit begin
2017-08-15 11:30:23,717 [main] INFO  ftpreader.FtpReader - read metadata from file begin
2017-08-15 11:30:23,718 [main] ERROR ftpreader.SftpHelper - 请确认您的配置项path:[/data1/test/testjsxf/__metadata]存在，且配置的用户有权限读取
2017-08-15 11:30:23,718 [main] ERROR ftpreader.FtpReader - init metadata error
请确认您的配置项path:[/data1/test/testjsxf/__metadata]存在，且配置的用户有权限读取
	at com.taobao.datax.plugins.reader.ftpreader.SftpHelper.isFileExist(SftpHelper.java:119)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.initMetadata(FtpReader.java:82)
	at com.taobao.datax.plugins.reader.ftpreader.FtpReader.split(FtpReader.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.taobao.datax.engine.schedule.PluginWorker.doSplit(PluginWorker.java:222)
	at com.taobao.datax.engine.schedule.Engine.initReaderPool(Engine.java:308)
	at com.taobao.datax.engine.schedule.Engine.start(Engine.java:96)
	at com.taobao.datax.engine.schedule.Engine.main(Engine.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-08-15 11:30:23,751 [main] INFO  ftpreader.FtpReader - 您即将读取的文件数为: [2]
2017-08-15 11:30:23,752 [main] INFO  schedule.PluginWorker - doSplit end
2017-08-15 11:30:23,761 [main] INFO  schedule.Engine - DataX Reader splits this job into 0 sub-jobs
2017-08-15 11:30:23,761 [main] INFO  schedule.Engine - DataX Reader split work ends .
2017-08-15 11:30:23,761 [main] INFO  schedule.Engine - DataX Reader starts to read data .
2017-08-15 11:30:23,761 [main] INFO  schedule.PluginWorker - init begin
2017-08-15 11:30:23,762 [main] INFO  schedule.PluginWorker - init end
2017-08-15 11:30:23,762 [main] INFO  schedule.Engine - DataX Writer prepare work begins .
2017-08-15 11:30:23,762 [main] INFO  schedule.PluginWorker - prepare begin
2017-08-15 11:30:23,762 [main] INFO  schedule.PluginWorker - prepare end
2017-08-15 11:30:23,762 [main] INFO  schedule.Engine - DataX Writer prepare work ends .
2017-08-15 11:30:23,762 [main] INFO  schedule.Engine - DataX Writer split work begins .
2017-08-15 11:30:23,762 [main] INFO  schedule.PluginWorker - doSplit begin
2017-08-15 11:30:23,762 [main] INFO  schedule.PluginWorker - doSplit end
2017-08-15 11:30:23,762 [main] INFO  schedule.Engine - DataX Writer splits this job into 1 sub-jobs .
2017-08-15 11:30:23,763 [main] INFO  schedule.Engine - DataX Writer split work ends .
2017-08-15 11:30:23,764 [main] INFO  schedule.Engine - DataX Writer starts to write data .
2017-08-15 11:30:23,764 [main] INFO  schedule.Engine - DataX starts to exchange data .
2017-08-15 11:30:23,766 [pool-8-thread-1] INFO  schedule.WriterWorker - begin execute finish in finally code:0
2017-08-15 11:30:23,766 [pool-8-thread-1] INFO  schedule.WriterWorker - execute finish in finally code:0
2017-08-15 11:30:23,767 [pool-8-thread-1] INFO  schedule.WriterWorker - call result msg:null is success:true
2017-08-15 11:30:24,766 [main] INFO  schedule.Engine - DataX Reader post work begins .
2017-08-15 11:30:24,766 [main] INFO  schedule.PluginWorker - post begin
2017-08-15 11:30:24,767 [main] INFO  schedule.PluginWorker - post end
2017-08-15 11:30:24,767 [main] INFO  schedule.Engine - DataX Reader post work ends .
2017-08-15 11:30:24,767 [main] INFO  schedule.Engine - DataX Writers post work begins .
2017-08-15 11:30:24,767 [main] INFO  schedule.PluginWorker - post begin
2017-08-15 11:30:24,767 [main] INFO  schedule.PluginWorker - post end
2017-08-15 11:30:24,767 [main] INFO  schedule.Engine - DataX Writers post work ends .
2017-08-15 11:30:24,767 [main] INFO  schedule.Engine - DataX job succeed .
2017-08-15 11:30:24,768 [main] INFO  schedule.Engine - check status twice begin
2017-08-15 11:30:24,768 [main] INFO  schedule.Engine - dps length:1
2017-08-15 11:30:24,768 [main] INFO  schedule.Engine - check status twice end
2017-08-15 11:30:24,770 [main] INFO  schedule.Engine - 
DataX starts work at      : 2017-08-15 11:30:23
DataX ends work at        : 2017-08-15 11:30:24
Total time costs          :                  1s
Average byte speed        :                0B/s
Average line speed        :                0L/s
Total transferred records :                   0
Total discarded records   :                   0

